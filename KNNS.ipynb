{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread, imshow\n",
    "from numpy import linalg as la\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = []\n",
    "y = []\n",
    "for i in range(1,100):\n",
    "    x.append(resize(cv2.imread('/Users/ayeshamoqeet/Desktop/ML/training_set/cats/cat.{}.jpg'.format(i)), (64, 32)))\n",
    "    y.append(0)\n",
    "for i in range(1,100):\n",
    "    x.append(resize(cv2.imread('/Users/ayeshamoqeet/Desktop/ML/training_set/dogs/dog.{}.jpg'.format(i)), (64, 32)))\n",
    "    y.append(1)\n",
    "\n",
    "x, y = np.asarray(x), np.asarray(y)\n",
    "\n",
    "x_train = []\n",
    "for i in range(198):\n",
    "    fd, hog_image = hog(x[i], orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
    "    x_train.append(fd)\n",
    "x_train = np.asarray(x_train)\n",
    "\n",
    "\n",
    "x_t = []\n",
    "y_t = []\n",
    "for i in range(1,100):\n",
    "    x_t.append(resize(io.imread('/Users/ayeshamoqeet/Desktop/ML/test_set/cats/cat.{}.jpg'.format(4000+i)), (64, 32)))\n",
    "    y_t.append(0)\n",
    "for i in range(1,100):\n",
    "    x_t.append(resize(io.imread('/Users/ayeshamoqeet/Desktop/ML/test_set/dogs/dog.{}.jpg'.format(4000+i)), (64, 32)))\n",
    "    y_t.append(1)\n",
    "y_t = np.array(y_t)\n",
    "\n",
    "x_test = []\n",
    "for i in range(198):\n",
    "    fdt, hog_image = hog(x_t[i], orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
    "    x_test.append(fdt)\n",
    "x_test = np.asarray(x_test)\n",
    "\n",
    "def Predict_without_tiebreaker(x_test,k,n):\n",
    "    predicted_results = []\n",
    "    for j in range(0,len(x_test)):\n",
    "        euclidean_distances = []\n",
    "        for i in range(0, len(x_train)):\n",
    "            euclidean_distances.append(la.norm((x_train[i] - x_test[j]), ord = n))\n",
    "            min_indexs = np.argsort(euclidean_distances)[:k]\n",
    "            y_ = y[min_indexs]\n",
    "            counts = np.bincount(y_)\n",
    "        predicted_results.append(np.argmax(counts))\n",
    "    return predicted_results\n",
    "\n",
    "def Predict(x_test,k,n):\n",
    "    predicted_results = []\n",
    "    for j in range(0,len(x_test)):\n",
    "        euclidean_distances = []\n",
    "        for i in range(0, len(x_train)):\n",
    "            euclidean_distances.append(la.norm((x_train[i] - x_test[j]), ord = n))\n",
    "            if k % 2 == 0:\n",
    "                min_indexs = np.argsort(euclidean_distances)[:k-1]\n",
    "            else:\n",
    "                min_indexs = np.argsort(euclidean_distances)[:k]\n",
    "            y_ = y[min_indexs]\n",
    "            counts = np.bincount(y_)\n",
    "        predicted_results.append(np.argmax(counts))\n",
    "    return predicted_results\n",
    "\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    tp = (y_true * y_pred).sum()\n",
    "    fp = ((1 - y_true) * y_pred).sum()\n",
    "    fn = (y_true * (1 - y_pred)).sum()\n",
    "    precision = tp / (tp + fp )\n",
    "    recall = tp / (tp + fn )\n",
    "    f1 =  2 * (precision * recall) / (precision + recall )\n",
    "    return f1\n",
    "\n",
    "\n",
    "\n",
    "def knn(n):\n",
    "    k_range = range(1, 8)\n",
    "    scores = {}\n",
    "    scores_list = []\n",
    "    confusion_matrix = {}\n",
    "    for k in k_range:\n",
    "        y_pred = Predict(x_test,k,n)\n",
    "        y_pred = np.array(y_pred)\n",
    "        scores[k] = f1_score(y_t, y_pred)\n",
    "        scores_list.append(f1_score(y_t, y_pred))\n",
    "        confusion_matrix[k] = pd.crosstab(pd.Series((y_t), name='Actual'), pd.Series(y_pred, name='Predicted'))\n",
    "    return scores_list, confusion_matrix\n",
    "\n",
    "\n",
    "Euclidean_f1, CM = knn(2)\n",
    "print(Euclidean_f1, CM)\n",
    "\n",
    "Manhattan_f1, CM2= knn(1)\n",
    "print(Manhattan_f1, CM2)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 8),Euclidean_f1 , color='red')\n",
    "plt.plot(range(1, 8),Manhattan_f1 , color='green', linestyle='dashed')\n",
    "\n",
    "plt.title('F1_score vs K')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('F1 score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in range(1,4001):\n",
    "    x.append(resize(cv2.imread('/Users/ayeshamoqeet/Desktop/ML/training_set/cats/cat.{}.jpg'.format(i)), (64, 32)))\n",
    "    y.append(0)\n",
    "    x.append(resize(cv2.imread('/Users/ayeshamoqeet/Desktop/ML/training_set/dogs/dog.{}.jpg'.format(i)), (64, 32)))\n",
    "    y.append(1)\n",
    "\n",
    "x, y = np.asarray(x), np.asarray(y)\n",
    "\n",
    "x_train = []\n",
    "for i in range(len(x)):\n",
    "    fd, hog_image = hog(x[i], orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
    "    x_train.append(fd)\n",
    "x_train = np.asarray(x_train)\n",
    "print(x_train.shape)\n",
    "\n",
    "\n",
    "x_t = []\n",
    "y_t = []\n",
    "for i in range(1,1001):\n",
    "    x_t.append(resize(cv2.imread('/Users/ayeshamoqeet/Desktop/ML/test_set/cats/cat.{}.jpg'.format(4000+i)), (64, 32)))\n",
    "    y_t.append(0)\n",
    "    x_t.append(resize(cv2.imread('/Users/ayeshamoqeet/Desktop/ML/test_set/dogs/dog.{}.jpg'.format(4000+i)), (64, 32)))\n",
    "    y_t.append(1)\n",
    "\n",
    "x_test = []\n",
    "for i in range(len(x_t)):\n",
    "    fdt, hog_image = hog(x_t[i], orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
    "    x_test.append(fdt)\n",
    "x_test = np.asarray(x_test)\n",
    "print(x_test.shape)\n",
    "\n",
    "\n",
    "def knn(n):\n",
    "    k_range = range(1, 8)\n",
    "    scores = {}\n",
    "    scores_list = []\n",
    "    scores_acc = {}\n",
    "    scores_acc_list = []\n",
    "    confusion_matrix = {}\n",
    "    for k in k_range:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, metric=n)\n",
    "        knn.fit(x_train, y)\n",
    "        y_pred = knn.predict(x_test)\n",
    "        scores[k] = f1_score(y_t, y_pred)\n",
    "        scores_list.append(f1_score(y_t, y_pred))\n",
    "        scores_acc[k] = metrics.accuracy_score(y_t, y_pred)\n",
    "        scores_acc_list.append(metrics.accuracy_score(y_t, y_pred))\n",
    "        confusion_matrix[k] = confusion_matrix(y_t, y_pred)\n",
    "\n",
    "    return scores_list, confusion_matrix, scores_acc_list\n",
    "\n",
    "Euclidean_f1, CM, Euclidean_acc  = knn('Euclidean')\n",
    "print(Euclidean_f1, CM, Euclidean_acc)\n",
    "\n",
    "Manhattan_f1, CM2, Manhattan_acc = knn('manhattan')\n",
    "print(Manhattan_f1, CM2, Manhattan_acc)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 8),Euclidean_f1 , color='red')\n",
    "plt.plot(range(1, 8),Manhattan_f1 , color='green', linestyle='dashed')\n",
    "plt.title('F1_score vs K')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('F1 score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRAIN = '/Users/ayeshamoqeet/Desktop/ML/Training data'\n",
    "\n",
    "data = []\n",
    "Categories = ['Cloudy', 'Rain', 'Shine', 'Sunrise']\n",
    "for category in Categories:\n",
    "    folder = os.path.join(TRAIN, category)\n",
    "    label = Categories.index(category)\n",
    "    for img in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, img)\n",
    "        img_array = cv2.imread(img_path)\n",
    "        data.append([img_array, label])\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for features, labels in data:\n",
    "    X.append(features)\n",
    "    Y.append(labels)\n",
    "\n",
    "X = np.array(X, dtype=object)\n",
    "Y = np.array(Y, dtype=int)\n",
    "\n",
    "\n",
    "resized_img = []\n",
    "\n",
    "for i in range(len(X)):\n",
    "    resized_img.append(resize(X[i], (32, 32)))\n",
    "\n",
    "resized_img = np.array(resized_img, dtype=object)\n",
    "x_train = resized_img.flatten().reshape(899, 3072)\n",
    "\n",
    "\n",
    "TEST = '/Users/ayeshamoqeet/Desktop/ML/Test data'\n",
    "datat = []\n",
    "Categoriest = ['Cloudy', 'Rain', 'Shine', 'Sunrise']\n",
    "for category in Categoriest:\n",
    "    folder = os.path.join(TEST, category)\n",
    "    labelt = Categoriest.index(category)\n",
    "    for img in os.listdir(folder):\n",
    "        img_patht = os.path.join(folder, img)\n",
    "        img_arrayt = cv2.imread(img_patht)\n",
    "        datat.append([img_arrayt, labelt])\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "for features, labels in datat:\n",
    "    X_test.append(features)\n",
    "    Y_test.append(labels)\n",
    "\n",
    "X_test = np.array(X_test)  # , dtype = object)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "resized_imgt = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    resized_imgt.append(resize(X_test[i], (32, 32)))\n",
    "\n",
    "\n",
    "resized_imgt = np.array(resized_imgt, dtype=object)\n",
    "X_test = resized_imgt.flatten().reshape(224, 3072)\n",
    "print(x_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "def Predict_without_tiebreaker(x_test,k,n):\n",
    "    predicted_results = []\n",
    "    for j in range(0,len(X_test)):\n",
    "        euclidean_distances = []\n",
    "        for i in range(0, len(x_train)):\n",
    "            euclidean_distances.append(la.norm((x_train[i] - X_test[j]), ord = n))\n",
    "            min_indexs = np.argsort(euclidean_distances)[:k]\n",
    "            y_ = y[min_indexs]\n",
    "            counts = np.bincount(y_)\n",
    "        predicted_results.append(np.argmax(counts))\n",
    "    return predicted_results\n",
    "\n",
    "def Predict(x_test,k,n):\n",
    "    predicted_results = []\n",
    "    for j in range(0,len(X_test)):\n",
    "        distances = []\n",
    "        for i in range(0, len(x_train)):\n",
    "            distances.append(la.norm((x_train[i] - X_test[j]), ord = n))\n",
    "            if k % 2 == 0:\n",
    "                min_indexs = np.argsort(distances)[:k-1]\n",
    "            else:\n",
    "                min_indexs = np.argsort(distances)[:k]\n",
    "            y_ = Y_test[min_indexs]\n",
    "            counts = np.bincount(y_)\n",
    "        predicted_results.append(np.argmax(counts))\n",
    "    return predicted_results\n",
    "\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    tp = (y_true * y_pred).sum()\n",
    "    fp = ((1 - y_true) * y_pred).sum()\n",
    "    fn = (y_true * (1 - y_pred)).sum()\n",
    "    precision = tp / (tp + fp )\n",
    "    recall = tp / (tp + fn )\n",
    "    f1 =  2 * (precision * recall) / (precision + recall )\n",
    "    return f1\n",
    "\n",
    "\n",
    "def knn(n):\n",
    "    k_range = range(1, 8)\n",
    "    scores = {}\n",
    "    scores_list = []\n",
    "    scores_acc = {}\n",
    "    scores_acc_list = []\n",
    "    confusion_matrix = {}\n",
    "    for k in k_range:\n",
    "        y_pred = Predict(X_test,k,n)\n",
    "        y_pred = np.array(y_pred)\n",
    "        scores[k] = f1_score((Y_test, y_pred), average='macro')\n",
    "        scores_list.append(f1_score(Y_test, y_pred), average = 'macro')\n",
    "        scores_acc[k] = metrics.accuracy_score(y_t, y_pred)\n",
    "        scores_acc_list.append(metrics.accuracy_score(y_t, y_pred))\n",
    "        confusion_matrix[k] = confusion_matrix(y_t, y_pred)\n",
    "    return scores_list, confusion_matrix, scores_acc_list\n",
    "\n",
    "Euclidean_f1, CM, Euclidean_acc = knn('Euclidean')\n",
    "print(Euclidean_f1, CM, Euclidean_acc)\n",
    "\n",
    "Manhattan_f1, CM2, Manhattan_acc = knn('manhattan')\n",
    "print(Manhattan_f1, CM2, Manhattan_acc)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 8), Euclidean_f1, color='red')\n",
    "plt.plot(range(1, 8), Manhattan_f1, color='green', linestyle='dashed')\n",
    "plt.title('F1_score vs K')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('F1 score')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
